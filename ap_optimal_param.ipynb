{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Install gower package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gower in d:\\pycharm\\pycharmprojects\\ap_test\\venv\\lib\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy in d:\\pycharm\\pycharmprojects\\ap_test\\venv\\lib\\site-packages (from gower) (1.18.0)\n",
      "Requirement already satisfied: scipy in d:\\pycharm\\pycharmprojects\\ap_test\\venv\\lib\\site-packages (from gower) (1.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'd:\\pycharm\\pycharmprojects\\ap_test\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install gower"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import  required packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gower\n",
    "import numpy as np\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select required attributes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "columns = ['estimatedp', 'wtr_srcdes', 'wtr_hauled', 'priv_wells', \\\n",
    "               'wc_exists', 'wc_adeq', 'wc_hlth', 'ww_public', 'ppl_nowat_r', 'ppl_noww_r', 'ppl_yeswat_r', 'ppl_yesww_r']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Specify file paths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "colonias_Y_path = 'dataset/colonias_Y_norm.csv'\n",
    "colonias_N_path = 'dataset/colonias_N_norm.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For Colonias with public water services"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   estimatedp           wtr_srcdes wtr_hauled priv_wells wc_exists wc_adeq  \\\n0         157  Public Water System          N          N         Y       Y   \n1          72  Public Water System          N          N         Y       Y   \n2         147  Public Water System          N          N         Y       Y   \n3          86  Public Water System          N          N         Y       Y   \n4          41  Public Water System          N          N         Y       Y   \n\n  wc_hlth ww_public  ppl_nowat_r  ppl_noww_r  ppl_yeswat_r  ppl_yesww_r  \n0       N         N          0.0         1.0           1.0          0.0  \n1       N         N          0.0         1.0           1.0          0.0  \n2       N         N          0.0         1.0           1.0          0.0  \n3       N         N          0.0         1.0           1.0          0.0  \n4       N         N          0.0         1.0           1.0          0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>estimatedp</th>\n      <th>wtr_srcdes</th>\n      <th>wtr_hauled</th>\n      <th>priv_wells</th>\n      <th>wc_exists</th>\n      <th>wc_adeq</th>\n      <th>wc_hlth</th>\n      <th>ww_public</th>\n      <th>ppl_nowat_r</th>\n      <th>ppl_noww_r</th>\n      <th>ppl_yeswat_r</th>\n      <th>ppl_yesww_r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>157</td>\n      <td>Public Water System</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>72</td>\n      <td>Public Water System</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>147</td>\n      <td>Public Water System</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>86</td>\n      <td>Public Water System</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n      <td>Public Water System</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Read corresponding csv file\n",
    "df = pd.read_csv(colonias_Y_path)[columns]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 2. Select records in which population rate is not larger than 1\n",
    "selected_df = df[(df['ppl_nowat_r'] <= 1) & (df['ppl_noww_r'] <= 1)\n",
    "                 & (df['ppl_yeswat_r'] <= 1) & (df['ppl_yesww_r'] <= 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Construct Similarity Metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 2.3611111e-04 2.7777778e-05 ... 7.7777775e-05\n",
      "  2.5289723e-01 3.3532500e-01]\n",
      " [2.3611111e-04 0.0000000e+00 2.0833334e-04 ... 1.5833334e-04\n",
      "  2.5313333e-01 3.3556110e-01]\n",
      " [2.7777778e-05 2.0833334e-04 0.0000000e+00 ... 4.9999999e-05\n",
      "  2.5292501e-01 3.3535278e-01]\n",
      " ...\n",
      " [7.7777775e-05 1.5833334e-04 4.9999999e-05 ... 0.0000000e+00\n",
      "  2.5297499e-01 3.3540279e-01]\n",
      " [2.5289723e-01 2.5313333e-01 2.5292501e-01 ... 2.5297499e-01\n",
      "  0.0000000e+00 8.4238887e-02]\n",
      " [3.3532500e-01 3.3556110e-01 3.3535278e-01 ... 3.3540279e-01\n",
      "  8.4238887e-02 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# use gower distance to construct similarity metric\n",
    "similarity_metric = gower.gower_matrix(selected_df)\n",
    "print(similarity_metric)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25000554\n"
     ]
    }
   ],
   "source": [
    "# Select median value in the similarity_metrix as the preference value (defined in Affinity Propagation algorithm)\n",
    "preference = np.median(similarity_metric)\n",
    "print(preference)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.5000554e-01 -2.3611111e-04 -2.7777778e-05 ... -7.7777775e-05\n",
      "  -2.5289723e-01 -3.3532500e-01]\n",
      " [-2.3611111e-04 -2.5000554e-01 -2.0833334e-04 ... -1.5833334e-04\n",
      "  -2.5313333e-01 -3.3556110e-01]\n",
      " [-2.7777778e-05 -2.0833334e-04 -2.5000554e-01 ... -4.9999999e-05\n",
      "  -2.5292501e-01 -3.3535278e-01]\n",
      " ...\n",
      " [-7.7777775e-05 -1.5833334e-04 -4.9999999e-05 ... -2.5000554e-01\n",
      "  -2.5297499e-01 -3.3540279e-01]\n",
      " [-2.5289723e-01 -2.5313333e-01 -2.5292501e-01 ... -2.5297499e-01\n",
      "  -2.5000554e-01 -8.4238887e-02]\n",
      " [-3.3532500e-01 -3.3556110e-01 -3.3535278e-01 ... -3.3540279e-01\n",
      "  -8.4238887e-02 -2.5000554e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Replace diagonal value with the preference value\n",
    "np.fill_diagonal(similarity_metric, preference)\n",
    "# Multiply with -1\n",
    "similarity_metric *= -1\n",
    "print(similarity_metric)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Applying Affinity Propagation and compare clustering results under different damping factors and iterations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dampings = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "iterations = range(200, 1050, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Damping= 0.5 , iteration= 200  n_clusters= 876 The average SScore= 0.43687734\n",
      "Damping= 0.5 , iteration= 250  n_clusters= 869 The average SScore= 0.43619883\n",
      "Damping= 0.5 , iteration= 300  n_clusters= 37 The average SScore= 0.8347605\n",
      "Damping= 0.5 , iteration= 350  n_clusters= 37 The average SScore= 0.8347605\n",
      "Damping= 0.5 , iteration= 400  n_clusters= 162 The average SScore= 0.43954504\n",
      "Damping= 0.5 , iteration= 450  n_clusters= 37 The average SScore= 0.8347605\n",
      "Damping= 0.5 , iteration= 500  n_clusters= 884 The average SScore= 0.437121\n",
      "Damping= 0.5 , iteration= 550  n_clusters= 868 The average SScore= 0.4371905\n",
      "Damping= 0.5 , iteration= 600  n_clusters= 884 The average SScore= 0.437121\n",
      "Damping= 0.5 , iteration= 650  n_clusters= 22 The average SScore= 0.8310452\n",
      "Damping= 0.5 , iteration= 700  n_clusters= 22 The average SScore= 0.8310452\n",
      "Damping= 0.5 , iteration= 750  n_clusters= 22 The average SScore= 0.8310452\n",
      "Damping= 0.5 , iteration= 800  n_clusters= 37 The average SScore= 0.8347605\n",
      "Damping= 0.5 , iteration= 850  n_clusters= 37 The average SScore= 0.8347605\n",
      "Damping= 0.5 , iteration= 900  n_clusters= 37 The average SScore= 0.8347605\n",
      "Damping= 0.5 , iteration= 950  n_clusters= 831 The average SScore= 0.4335142\n",
      "Damping= 0.5 , iteration= 1000  n_clusters= 837 The average SScore= 0.4336296\n",
      "Damping= 0.6 , iteration= 200  n_clusters= 791 The average SScore= 0.43102053\n",
      "Damping= 0.6 , iteration= 250  n_clusters= 824 The average SScore= 0.44005\n",
      "Damping= 0.6 , iteration= 300  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 350  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 400  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 450  n_clusters= 826 The average SScore= 0.4399345\n",
      "Damping= 0.6 , iteration= 500  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 550  n_clusters= 100 The average SScore= 0.4448468\n",
      "Damping= 0.6 , iteration= 600  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 650  n_clusters= 814 The average SScore= 0.4342264\n",
      "Damping= 0.6 , iteration= 700  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 750  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 800  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 850  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 900  n_clusters= 777 The average SScore= 0.44016388\n",
      "Damping= 0.6 , iteration= 950  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.6 , iteration= 1000  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 200  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 250  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 300  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 350  n_clusters= 777 The average SScore= 0.44002402\n",
      "Damping= 0.7 , iteration= 400  n_clusters= 666 The average SScore= 0.4397603\n",
      "Damping= 0.7 , iteration= 450  n_clusters= 774 The average SScore= 0.4400342\n",
      "Damping= 0.7 , iteration= 500  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 550  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 600  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 650  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 700  n_clusters= 809 The average SScore= 0.4397382\n",
      "Damping= 0.7 , iteration= 750  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 800  n_clusters= 818 The average SScore= 0.43964812\n",
      "Damping= 0.7 , iteration= 850  n_clusters= 792 The average SScore= 0.43984973\n",
      "Damping= 0.7 , iteration= 900  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.7 , iteration= 950  n_clusters= 791 The average SScore= 0.43151063\n",
      "Damping= 0.7 , iteration= 1000  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.8 , iteration= 200  n_clusters= 721 The average SScore= 0.42980173\n",
      "Damping= 0.8 , iteration= 250  n_clusters= 1224 The average SScore= 0.023165086\n",
      "Damping= 0.8 , iteration= 300  n_clusters= 569 The average SScore= 0.4256739\n",
      "Damping= 0.8 , iteration= 350  n_clusters= 315 The average SScore= 0.42405364\n",
      "Damping= 0.8 , iteration= 400  n_clusters= 1333 The average SScore= 0.023220615\n",
      "Damping= 0.8 , iteration= 450  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.8 , iteration= 500  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.8 , iteration= 550  n_clusters= 647 The average SScore= 0.42963204\n",
      "Damping= 0.8 , iteration= 600  n_clusters= 781 The average SScore= 0.43997318\n",
      "Damping= 0.8 , iteration= 650  n_clusters= 783 The average SScore= 0.4397591\n",
      "Damping= 0.8 , iteration= 700  n_clusters= 25 The average SScore= 0.662817\n",
      "Damping= 0.8 , iteration= 750  n_clusters= 486 The average SScore= 0.43305346\n",
      "Damping= 0.8 , iteration= 800  n_clusters= 999 The average SScore= 0.016430233\n",
      "Damping= 0.8 , iteration= 850  n_clusters= 560 The average SScore= 0.4256678\n",
      "Damping= 0.8 , iteration= 900  n_clusters= 503 The average SScore= 0.43294612\n",
      "Damping= 0.8 , iteration= 950  n_clusters= 305 The average SScore= 0.4310451\n",
      "Damping= 0.8 , iteration= 1000  n_clusters= 24 The average SScore= 0.8435476\n",
      "Damping= 0.9 , iteration= 200  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 250  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 300  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 350  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 400  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 450  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 500  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 550  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 600  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 650  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 700  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 750  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 800  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 850  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 900  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 950  n_clusters= 23 The average SScore= 0.83953947\n",
      "Damping= 0.9 , iteration= 1000  n_clusters= 23 The average SScore= 0.83953947\n"
     ]
    }
   ],
   "source": [
    "for damping in dampings:\n",
    "    for i in iterations:\n",
    "        # Apply calculated similarity_metric to AP algorithm\n",
    "        af = AffinityPropagation(affinity='precomputed', damping=damping, max_iter=i).fit(similarity_metric)\n",
    "        # Get the number of clusters\n",
    "        n_clusters = len(np.unique(af.labels_))\n",
    "        # Get corresponding labels\n",
    "        cluster_labels = af.labels_\n",
    "        # Calculate silhouette score\n",
    "        silhouette_avg = metrics.silhouette_score(similarity_metric, cluster_labels)\n",
    "        print('Damping=', damping, ', iteration=', i, ' n_clusters=', n_clusters,\n",
    "              'The average SScore=', silhouette_avg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For Colonias without public water services"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   estimatedp     wtr_srcdes wtr_hauled priv_wells wc_exists wc_adeq wc_hlth  \\\n0          67  Private Wells          N          Y         N       N       N   \n1          16  Private Wells          N          Y         N       N       N   \n2          46  Private Wells          N          Y         N       N       N   \n3         181  Private Wells          N          Y         N       N       N   \n4         293  Private Wells          N          Y         N       N       N   \n\n  ww_public  ppl_nowat_r  ppl_noww_r  ppl_yeswat_r  ppl_yesww_r  \n0         N          1.0         1.0           0.0          0.0  \n1         N          1.0         1.0           0.0          0.0  \n2         N          1.0         1.0           0.0          0.0  \n3         N          1.0         1.0           0.0          0.0  \n4         N          1.0         1.0           0.0          0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>estimatedp</th>\n      <th>wtr_srcdes</th>\n      <th>wtr_hauled</th>\n      <th>priv_wells</th>\n      <th>wc_exists</th>\n      <th>wc_adeq</th>\n      <th>wc_hlth</th>\n      <th>ww_public</th>\n      <th>ppl_nowat_r</th>\n      <th>ppl_noww_r</th>\n      <th>ppl_yeswat_r</th>\n      <th>ppl_yesww_r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>67</td>\n      <td>Private Wells</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n      <td>Private Wells</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46</td>\n      <td>Private Wells</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>181</td>\n      <td>Private Wells</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>293</td>\n      <td>Private Wells</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Read corresponding csv file\n",
    "df = pd.read_csv(colonias_N_path)[columns]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 2. Select records in which population rate is not larger than 1\n",
    "selected_df = df[(df['ppl_nowat_r'] <= 1) & (df['ppl_noww_r'] <= 1)\n",
    "                 & (df['ppl_yeswat_r'] <= 1) & (df['ppl_yesww_r'] <= 1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Construct Similarity Metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 5.0595240e-04 2.0833334e-04 ... 3.3365080e-01\n",
      "  3.3578372e-01 3.3485121e-01]\n",
      " [5.0595240e-04 0.0000000e+00 2.9761906e-04 ... 3.3352181e-01\n",
      "  3.3628967e-01 3.3535713e-01]\n",
      " [2.0833334e-04 2.9761906e-04 0.0000000e+00 ... 3.3344245e-01\n",
      "  3.3599207e-01 3.3505952e-01]\n",
      " ...\n",
      " [3.3365080e-01 3.3352181e-01 3.3344245e-01 ... 0.0000000e+00\n",
      "  2.7678572e-03 1.8353175e-03]\n",
      " [3.3578372e-01 3.3628967e-01 3.3599207e-01 ... 2.7678572e-03\n",
      "  0.0000000e+00 9.3253970e-04]\n",
      " [3.3485121e-01 3.3535713e-01 3.3505952e-01 ... 1.8353175e-03\n",
      "  9.3253970e-04 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# use gower distance to construct similarity metric\n",
    "similarity_metric = gower.gower_matrix(selected_df)\n",
    "print(similarity_metric)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3336508\n"
     ]
    }
   ],
   "source": [
    "# Select median value in the similarity_metrix as the preference value (defined in Affinity Propagation algorithm)\n",
    "preference = np.median(similarity_metric)\n",
    "print(preference)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.3365080e-01 -5.0595240e-04 -2.0833334e-04 ... -3.3365080e-01\n",
      "  -3.3578372e-01 -3.3485121e-01]\n",
      " [-5.0595240e-04 -3.3365080e-01 -2.9761906e-04 ... -3.3352181e-01\n",
      "  -3.3628967e-01 -3.3535713e-01]\n",
      " [-2.0833334e-04 -2.9761906e-04 -3.3365080e-01 ... -3.3344245e-01\n",
      "  -3.3599207e-01 -3.3505952e-01]\n",
      " ...\n",
      " [-3.3365080e-01 -3.3352181e-01 -3.3344245e-01 ... -3.3365080e-01\n",
      "  -2.7678572e-03 -1.8353175e-03]\n",
      " [-3.3578372e-01 -3.3628967e-01 -3.3599207e-01 ... -2.7678572e-03\n",
      "  -3.3365080e-01 -9.3253970e-04]\n",
      " [-3.3485121e-01 -3.3535713e-01 -3.3505952e-01 ... -1.8353175e-03\n",
      "  -9.3253970e-04 -3.3365080e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Replace diagonal value with the preference value\n",
    "np.fill_diagonal(similarity_metric, preference)\n",
    "# Multiply with -1\n",
    "similarity_metric *= -1\n",
    "print(similarity_metric)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Applying Affinity Propagation and compare clustering results under different damping factors and iterations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "dampings = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "iterations = range(200, 1050, 50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Damping= 0.5 , iteration= 200  n_clusters= 11 The average SScore= 0.43082762\n",
      "Damping= 0.5 , iteration= 250  n_clusters= 112 The average SScore= 0.28626224\n",
      "Damping= 0.5 , iteration= 300  n_clusters= 59 The average SScore= 0.28480664\n",
      "Damping= 0.5 , iteration= 350  n_clusters= 68 The average SScore= 0.4302451\n",
      "Damping= 0.5 , iteration= 400  n_clusters= 116 The average SScore= 0.28634334\n",
      "Damping= 0.5 , iteration= 450  n_clusters= 59 The average SScore= 0.28480664\n",
      "Damping= 0.5 , iteration= 500  n_clusters= 111 The average SScore= 0.28619343\n",
      "Damping= 0.5 , iteration= 550  n_clusters= 116 The average SScore= 0.28634334\n",
      "Damping= 0.5 , iteration= 600  n_clusters= 116 The average SScore= 0.28634334\n",
      "Damping= 0.5 , iteration= 650  n_clusters= 11 The average SScore= 0.43082762\n",
      "Damping= 0.5 , iteration= 700  n_clusters= 59 The average SScore= 0.28480664\n",
      "Damping= 0.5 , iteration= 750  n_clusters= 66 The average SScore= 0.43016735\n",
      "Damping= 0.5 , iteration= 800  n_clusters= 116 The average SScore= 0.28634334\n",
      "Damping= 0.5 , iteration= 850  n_clusters= 59 The average SScore= 0.28480664\n",
      "Damping= 0.5 , iteration= 900  n_clusters= 68 The average SScore= 0.4302451\n",
      "Damping= 0.5 , iteration= 950  n_clusters= 11 The average SScore= 0.43082762\n",
      "Damping= 0.5 , iteration= 1000  n_clusters= 68 The average SScore= 0.4302451\n",
      "Damping= 0.6 , iteration= 200  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 250  n_clusters= 58 The average SScore= 0.44657227\n",
      "Damping= 0.6 , iteration= 300  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 350  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 400  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 450  n_clusters= 59 The average SScore= 0.4466154\n",
      "Damping= 0.6 , iteration= 500  n_clusters= 11 The average SScore= 0.6063733\n",
      "Damping= 0.6 , iteration= 550  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 600  n_clusters= 57 The average SScore= 0.4465864\n",
      "Damping= 0.6 , iteration= 650  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 700  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 750  n_clusters= 58 The average SScore= 0.4466142\n",
      "Damping= 0.6 , iteration= 800  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 850  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 900  n_clusters= 60 The average SScore= 0.4466615\n",
      "Damping= 0.6 , iteration= 950  n_clusters= 59 The average SScore= 0.43702045\n",
      "Damping= 0.6 , iteration= 1000  n_clusters= 50 The average SScore= 0.4465946\n",
      "Damping= 0.7 , iteration= 200  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 250  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 300  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 350  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 400  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 450  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 500  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 550  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 600  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 650  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 700  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 750  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 800  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 850  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 900  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 950  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.7 , iteration= 1000  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 200  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 250  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 300  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 350  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 400  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 450  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 500  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 550  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 600  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 650  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 700  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 750  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 800  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 850  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 900  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 950  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.8 , iteration= 1000  n_clusters= 12 The average SScore= 0.57841134\n",
      "Damping= 0.9 , iteration= 200  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 250  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 300  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 350  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 400  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 450  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 500  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 550  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 600  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 650  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 700  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 750  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 800  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 850  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 900  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 950  n_clusters= 11 The average SScore= 0.5917159\n",
      "Damping= 0.9 , iteration= 1000  n_clusters= 11 The average SScore= 0.5917159\n"
     ]
    }
   ],
   "source": [
    "for damping in dampings:\n",
    "    for i in iterations:\n",
    "        # Apply calculated similarity_metric to AP algorithm\n",
    "        af = AffinityPropagation(affinity='precomputed', damping=damping, max_iter=i).fit(similarity_metric)\n",
    "        # Get the number of clusters\n",
    "        n_clusters = len(np.unique(af.labels_))\n",
    "        # Get corresponding labels\n",
    "        cluster_labels = af.labels_\n",
    "        # Calculate silhouette score\n",
    "        silhouette_avg = metrics.silhouette_score(similarity_metric, cluster_labels)\n",
    "        print('Damping=', damping, ', iteration=', i, ' n_clusters=', n_clusters,\n",
    "              'The average SScore=', silhouette_avg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}